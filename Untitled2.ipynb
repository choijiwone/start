{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae37a78-06de-4267-8db5-a93f43032c69",
   "metadata": {},
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news_data = fetch_20newsgroups(subset='all',random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc4b43e2-9432-4ef0-b0a8-b5ae6307c348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(news_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb593f94-d9bc-47a4-b325-84a33f10da3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target 클래스의 값과 분포도 \n",
      " 0     799\n",
      "1     973\n",
      "2     985\n",
      "3     982\n",
      "4     963\n",
      "5     988\n",
      "6     975\n",
      "7     990\n",
      "8     996\n",
      "9     994\n",
      "10    999\n",
      "11    991\n",
      "12    984\n",
      "13    990\n",
      "14    987\n",
      "15    997\n",
      "16    910\n",
      "17    940\n",
      "18    775\n",
      "19    628\n",
      "Name: count, dtype: int64\n",
      "target 클래스의 이름들 \n",
      " ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print('target 클래스의 값과 분포도 \\n',pd.Series(news_data.target).value_counts().sort_index())\n",
    "print('target 클래스의 이름들 \\n',news_data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2cd190e-808b-41f1-aaba-1168148c325b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: egreen@east.sun.com (Ed Green - Pixel Cruncher)\n",
      "Subject: Re: Observation re: helmets\n",
      "Organization: Sun Microsystems, RTP, NC\n",
      "Lines: 21\n",
      "Distribution: world\n",
      "Reply-To: egreen@east.sun.com\n",
      "NNTP-Posting-Host: laser.east.sun.com\n",
      "\n",
      "In article 211353@mavenry.altcit.eskimo.com, maven@mavenry.altcit.eskimo.com (Norman Hamer) writes:\n",
      "> \n",
      "> The question for the day is re: passenger helmets, if you don't know for \n",
      ">certain who's gonna ride with you (like say you meet them at a .... church \n",
      ">meeting, yeah, that's the ticket)... What are some guidelines? Should I just \n",
      ">pick up another shoei in my size to have a backup helmet (XL), or should I \n",
      ">maybe get an inexpensive one of a smaller size to accomodate my likely \n",
      ">passenger? \n",
      "\n",
      "If your primary concern is protecting the passenger in the event of a\n",
      "crash, have him or her fitted for a helmet that is their size.  If your\n",
      "primary concern is complying with stupid helmet laws, carry a real big\n",
      "spare (you can put a big or small head in a big helmet, but not in a\n",
      "small one).\n",
      "\n",
      "---\n",
      "Ed Green, former Ninjaite |I was drinking last night with a biker,\n",
      "  Ed.Green@East.Sun.COM   |and I showed him a picture of you.  I said,\n",
      "DoD #0111  (919)460-8302  |\"Go on, get to know her, you'll like her!\"\n",
      " (The Grateful Dead) -->  |It seemed like the least I could do...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(news_data.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5e46f-4792-41b3-a913-970c6ec359c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# subset='train'으로 학습용(Train) 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
    "train_news= fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), random_state=156)\n",
    "X_train = train_news.data\n",
    "y_train = train_news.target\n",
    "print(type(X_train))\n",
    "\n",
    "# subset='test'으로 테스트(Test) 데이터만 추출, remove=('headers', 'footers', 'quotes')로 내용만 추출\n",
    "test_news= fetch_20newsgroups(subset='test',remove=('headers', 'footers','quotes'),random_state=156)\n",
    "X_test = test_news.data\n",
    "y_test = test_news.target\n",
    "print('학습 데이터 크기 {0} , 테스트 데이터 크기 {1}'.format(len(train_news.data) , len(test_news.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f34483-cd13-4e68-a734-6105e4c926bc",
   "metadata": {},
   "source": [
    "### 지도학습 기반 감성 분석 실습 – IMDB 영화평"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab360c48-8feb-4fbc-a40c-46b429368401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "review_df = pd.read_csv('./labeledTrainData.tsv', header=0, sep=\"\\t\", quoting=3)\n",
    "review_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80d495c2-4d65-465f-8079-25a41eb659bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I saw this movie as a child and it broke my heart! No other story had such a unfinished ending... I grew up on many great anime movies and this was one of my favourites, because it was so unusual - a story about unfairness, and cruelty, and loneliness, and life, and choices that can't be undone, and the need for others. Chirin is made alone when the Wolf kills his mother, but the Wolf is alone, too, when Chirin follows him into the mountain. The Wolf doesn't kill the lamb, even though each night he says \\\"maybe I'll eat you tomorrow.\\\" The tape of it I have is broken and degraded from age and use. I will repair it and watch the movie again someday and cry just as hard as I did as a child. Stories like this, with this depth and feeling, and this intricacy of meaning, are very rare. It is a sad story, but I've never encountered any catharsis more beautifully made. I am glad I have seen this movie, and I'm glad I saw it as a child.\"\n"
     ]
    }
   ],
   "source": [
    "print(review_df['review'][24999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "144598c4-3be0-4cb1-b49f-9b5c81aa825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5316ab3-7315-4652-bfea-6a9eb6b36bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "353825de-df83-418c-af3c-bad39b6a2c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('plays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddf21c4c-feb9-4b6c-a9a7-b77dd8d4f286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\admin/nltk_data'\n    - 'C:\\\\Program Files\\\\Python310\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\Python310\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\Python310\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\admin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mI played baseball\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\nltk\\tokenize\\__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m     ]\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\nltk\\tokenize\\__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlanguage\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\nltk\\data.py:750\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m \u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\nltk\\data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen()\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[0;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\admin/nltk_data'\n    - 'C:\\\\Program Files\\\\Python310\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\Python310\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\Python310\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\admin\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "word_tokenize('I played baseball') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65a355b0-fa66-4265-8991-ae49229f7e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 원본 행렬 R 생성, 분해 행렬 P와 Q 초기화, 잠재요인 차원 K는 3 설정. \n",
    "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN ],\n",
    "              [np.NaN, 5, np.NaN, 3, 1 ],\n",
    "              [np.NaN, np.NaN, 3, 4, 4 ],\n",
    "              [5, 2, 1, 2, np.NaN ]])\n",
    "num_users, num_items = R.shape\n",
    "K=3\n",
    "\n",
    "# P와 Q 매트릭스의 크기를 지정하고 정규분포를 가진 random한 값으로 입력합니다. \n",
    "np.random.seed(1)\n",
    "P = np.random.normal(scale=1./K, size=(num_users, K))\n",
    "Q = np.random.normal(scale=1./K, size=(num_items, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfffa62f-b2f8-4f2c-b213-f0716e67f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(R, P, Q, non_zeros):\n",
    "    error = 0\n",
    "    # 두개의 분해된 행렬 P와 Q.T의 내적으로 예측 R 행렬 생성\n",
    "    full_pred_matrix = np.dot(P, Q.T)\n",
    "    \n",
    "    # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출하여 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "      \n",
    "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13928d65-7d52-4b40-8748-0d13d9dd4f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### iteration step :  0  rmse :  3.2388050277987723\n",
      "### iteration step :  50  rmse :  0.4876723101369647\n",
      "### iteration step :  100  rmse :  0.15643403848192458\n",
      "### iteration step :  150  rmse :  0.07455141311978064\n",
      "### iteration step :  200  rmse :  0.043252267985793146\n",
      "### iteration step :  250  rmse :  0.029248328780879226\n",
      "### iteration step :  300  rmse :  0.022621116143829507\n",
      "### iteration step :  350  rmse :  0.019493636196525232\n",
      "### iteration step :  400  rmse :  0.018022719092132773\n",
      "### iteration step :  450  rmse :  0.01731968595344283\n",
      "### iteration step :  500  rmse :  0.016973657887570985\n",
      "### iteration step :  550  rmse :  0.01679680459589558\n",
      "### iteration step :  600  rmse :  0.016701322901884634\n",
      "### iteration step :  650  rmse :  0.016644736912476574\n",
      "### iteration step :  700  rmse :  0.016605910068210012\n",
      "### iteration step :  750  rmse :  0.01657420047570488\n",
      "### iteration step :  800  rmse :  0.01654431582921612\n",
      "### iteration step :  850  rmse :  0.016513751774735037\n",
      "### iteration step :  900  rmse :  0.01648146573819507\n",
      "### iteration step :  950  rmse :  0.01644717168347911\n"
     ]
    }
   ],
   "source": [
    "# R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장. \n",
    "non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n",
    "\n",
    "steps=1000\n",
    "learning_rate=0.01\n",
    "r_lambda=0.01\n",
    "\n",
    "# SGD 기법으로 P와 Q 매트릭스를 계속 업데이트. \n",
    "for step in range(steps):\n",
    "    for i, j, r in non_zeros:\n",
    "        # 실제 값과 예측 값의 차이인 오류 값 구함\n",
    "        eij = r - np.dot(P[i, :], Q[j, :].T)\n",
    "        # Regularization을 반영한 SGD 업데이트 공식 적용\n",
    "        P[i,:] = P[i,:] + learning_rate*(eij * Q[j, :] - r_lambda*P[i,:])\n",
    "        Q[j,:] = Q[j,:] + learning_rate*(eij * P[i, :] - r_lambda*Q[j,:])\n",
    "\n",
    "    rmse = get_rmse(R, P, Q, non_zeros)\n",
    "    if (step % 50) == 0 :\n",
    "        print(\"### iteration step : \", step,\" rmse : \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9c4c33c-5229-47dd-81be-dd77c962023f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4803, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                             genres  \\\n",
       "0  237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "\n",
       "                      homepage     id  \\\n",
       "0  http://www.avatarmovie.com/  19995   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "\n",
       "  original_title                                           overview  \\\n",
       "0         Avatar  In the 22nd century, a paraplegic Marine is di...   \n",
       "\n",
       "   popularity                               production_companies  \\\n",
       "0  150.437577  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
       "\n",
       "                                production_countries release_date     revenue  \\\n",
       "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10  2787965087   \n",
       "\n",
       "   runtime                                   spoken_languages    status  \\\n",
       "0    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
       "\n",
       "                       tagline   title  vote_average  vote_count  \n",
       "0  Enter the World of Pandora.  Avatar           7.2       11800  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "movies =pd.read_csv('./tmdb_5000_movies.csv')\n",
    "print(movies.shape)\n",
    "movies.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11199ebe-f06f-4f7d-96d5-19e06e3306af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4803, 8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = movies[['id','title', 'genres', 'vote_average', 'vote_count',\n",
    "                 'popularity', 'keywords', 'overview']]\n",
    "\n",
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2c991e9-ec64-4568-99d0-726865d92f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {...</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\": 2964, \"name\": \"future\"}, {\"id\": 3386, \"name\": \"sp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                genres  \\\n",
       "0  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {...   \n",
       "\n",
       "                                                                                              keywords  \n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\": 2964, \"name\": \"future\"}, {\"id\": 3386, \"name\": \"sp...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 100)\n",
    "movies_df[['genres','keywords']][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9cc1a96-35d8-4e76-bccd-88c0ac1c14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "movies_df['genres'] = movies_df['genres'].apply(literal_eval)\n",
    "movies_df['keywords'] = movies_df['keywords'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24498c69-e787-466d-9e85-bd5d8d1aefc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>popularity</th>\n",
       "      <th>keywords</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres_literal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>[Action, Adventure, Fantasy, Science Fiction]</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[culture clash, future, space war, space colony, society, space travel, futuristic, romance, spa...</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, ...</td>\n",
       "      <td>Action Adventure Fantasy Science Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>[Adventure, Fantasy, Action]</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[ocean, drug abuse, exotic island, east india trading company, love of one's life, traitor, ship...</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, has come back to life and is headed to the edge of t...</td>\n",
       "      <td>Adventure Fantasy Action</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                     title  \\\n",
       "0  19995                                    Avatar   \n",
       "1    285  Pirates of the Caribbean: At World's End   \n",
       "\n",
       "                                          genres  vote_average  vote_count  \\\n",
       "0  [Action, Adventure, Fantasy, Science Fiction]           7.2       11800   \n",
       "1                   [Adventure, Fantasy, Action]           6.9        4500   \n",
       "\n",
       "   popularity  \\\n",
       "0  150.437577   \n",
       "1  139.082615   \n",
       "\n",
       "                                                                                              keywords  \\\n",
       "0  [culture clash, future, space war, space colony, society, space travel, futuristic, romance, spa...   \n",
       "1  [ocean, drug abuse, exotic island, east india trading company, love of one's life, traitor, ship...   \n",
       "\n",
       "                                                                                              overview  \\\n",
       "0  In the 22nd century, a paraplegic Marine is dispatched to the moon Pandora on a unique mission, ...   \n",
       "1  Captain Barbossa, long believed to be dead, has come back to life and is headed to the edge of t...   \n",
       "\n",
       "                             genres_literal  \n",
       "0  Action Adventure Fantasy Science Fiction  \n",
       "1                  Adventure Fantasy Action  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dddaef49-f426-4697-a61d-feafc69595c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Action, Adventure, Fantasy, Science Fiction]</td>\n",
       "      <td>[culture clash, future, space war, space colony, society, space travel, futuristic, romance, spa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          genres  \\\n",
       "0  [Action, Adventure, Fantasy, Science Fiction]   \n",
       "\n",
       "                                                                                              keywords  \n",
       "0  [culture clash, future, space war, space colony, society, space travel, futuristic, romance, spa...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df['genres'] = movies_df['genres'].apply(lambda x : [ y['name'] for y in x])\n",
    "movies_df['keywords'] = movies_df['keywords'].apply(lambda x : [ y['name'] for y in x])\n",
    "movies_df[['genres', 'keywords']][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84dca3b1-27ac-485f-b211-7b782dc61f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4803, 176)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# CountVectorizer를 적용하기 위해 공백문자로 word 단위가 구분되는 문자열로 변환. \n",
    "movies_df['genres_literal'] = movies_df['genres'].apply(lambda x : (' ').join(x))\n",
    "count_vect = CountVectorizer(min_df=0.001, ngram_range=(1,2))\n",
    "genre_mat = count_vect.fit_transform(movies_df['genres_literal'])\n",
    "print(genre_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55dc3ab1-e9e3-4fcf-b7b3-85e06cede682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4803x176 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 20429 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d1794cc-57d3-48e8-8dbc-2fc881c06c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4803, 4803)\n",
      "[[1.         0.59628479 0.4472136  ... 0.         0.         0.        ]\n",
      " [0.59628479 1.         0.4        ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "genre_sim = cosine_similarity(genre_mat, genre_mat)\n",
    "print(genre_sim.shape)\n",
    "print(genre_sim[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26a024c5-df2c-41db-b8db-5046f7e6f2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   14  813 ... 3038 3037 2401]]\n"
     ]
    }
   ],
   "source": [
    "genre_sim_sorted_ind = genre_sim.argsort()[:, ::-1]\n",
    "print(genre_sim_sorted_ind[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3c3cd50-30f4-4864-9878-2d736d35ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sim_movie(df, sorted_ind, title_name, top_n=10):\n",
    "    \n",
    "    # 인자로 입력된 movies_df DataFrame에서 'title' 컬럼이 입력된 title_name 값인 DataFrame추출\n",
    "    title_movie = df[df['title'] == title_name]\n",
    "    \n",
    "    # title_named을 가진 DataFrame의 index 객체를 ndarray로 반환하고 \n",
    "    # sorted_ind 인자로 입력된 genre_sim_sorted_ind 객체에서 유사도 순으로 top_n 개의 index 추출\n",
    "    title_index = title_movie.index.values\n",
    "    similar_indexes = sorted_ind[title_index, :(top_n)]\n",
    "    \n",
    "    # 추출된 top_n index들 출력. top_n index는 2차원 데이터 임. \n",
    "    #dataframe에서 index로 사용하기 위해서 1차원 array로 변경\n",
    "    print(similar_indexes)\n",
    "    similar_indexes = similar_indexes.reshape(-1)\n",
    "    \n",
    "    return df.iloc[similar_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e17962f6-cf7c-4f9d-9987-94bb49cd7f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1243 3594 1946 1464 4065 4041 1663  281 1847 1370]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>Mean Streets</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>Spring Breakers</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>The Bad Lieutenant: Port of Call - New Orleans</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>Black Water Transit</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>Mi America</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>This Is England</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>Once Upon a Time in America</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>American Gangster</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>GoodFellas</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>21</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  vote_average\n",
       "1243                                    Mean Streets           7.2\n",
       "3594                                 Spring Breakers           5.0\n",
       "1946  The Bad Lieutenant: Port of Call - New Orleans           6.0\n",
       "1464                             Black Water Transit           0.0\n",
       "4065                                      Mi America           0.0\n",
       "4041                                 This Is England           7.4\n",
       "1663                     Once Upon a Time in America           8.2\n",
       "281                                American Gangster           7.4\n",
       "1847                                      GoodFellas           8.2\n",
       "1370                                              21           6.5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_movies = find_sim_movie(movies_df, genre_sim_sorted_ind, 'The Godfather',10)\n",
    "similar_movies[['title', 'vote_average']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7511c52e-9ec9-4739-99ba-bab95f64da61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>Stiff Upper Lips</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>Me You and Five Bucks</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>Dancer, Texas Pop. 81</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>Little Big Top</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>Sardaarji</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>One Man's Hero</td>\n",
       "      <td>9.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>There Goes My Baby</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>The Prisoner of Zenda</td>\n",
       "      <td>8.4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  vote_average  vote_count\n",
       "3519          Stiff Upper Lips          10.0           1\n",
       "4247     Me You and Five Bucks          10.0           2\n",
       "4045     Dancer, Texas Pop. 81          10.0           1\n",
       "4662            Little Big Top          10.0           1\n",
       "3992                 Sardaarji           9.5           2\n",
       "2386            One Man's Hero           9.3           2\n",
       "2970        There Goes My Baby           8.5           2\n",
       "1881  The Shawshank Redemption           8.5        8205\n",
       "2796     The Prisoner of Zenda           8.4          11\n",
       "3337             The Godfather           8.4        5893"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df[['title','vote_average','vote_count']].sort_values('vote_average', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5be15151-9086-4620-a754-921ca1263482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 6.092 m: 370.2\n"
     ]
    }
   ],
   "source": [
    "C = movies_df['vote_average'].mean()\n",
    "m = movies_df['vote_count'].quantile(0.6)\n",
    "print('C:',round(C,3), 'm:',round(m,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "24230b5a-6914-4da6-9b62-05f784ee4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = 0.6\n",
    "m = movies_df['vote_count'].quantile(percentile)\n",
    "C = movies_df['vote_average'].mean()\n",
    "\n",
    "def weighted_vote_average(record):\n",
    "    v = record['vote_count']\n",
    "    R = record['vote_average']\n",
    "    \n",
    "    return ( (v/(v+m)) * R ) + ( (m/(m+v)) * C )   \n",
    "\n",
    "movies_df['weighted_vote'] = movies_df.apply(weighted_vote_average, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "28db1d04-1f83-48ac-ba86-38e2e91f981f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>weighted_vote</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.396052</td>\n",
       "      <td>8205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.263591</td>\n",
       "      <td>5893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.216455</td>\n",
       "      <td>9413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.207102</td>\n",
       "      <td>8428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.136930</td>\n",
       "      <td>12002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.126069</td>\n",
       "      <td>4329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3865</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.123248</td>\n",
       "      <td>4254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.105954</td>\n",
       "      <td>7927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>Spirited Away</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.105867</td>\n",
       "      <td>3840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.079586</td>\n",
       "      <td>3338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  vote_average  weighted_vote  vote_count\n",
       "1881  The Shawshank Redemption           8.5       8.396052        8205\n",
       "3337             The Godfather           8.4       8.263591        5893\n",
       "662                 Fight Club           8.3       8.216455        9413\n",
       "3232              Pulp Fiction           8.3       8.207102        8428\n",
       "65             The Dark Knight           8.2       8.136930       12002\n",
       "1818          Schindler's List           8.3       8.126069        4329\n",
       "3865                  Whiplash           8.3       8.123248        4254\n",
       "809               Forrest Gump           8.2       8.105954        7927\n",
       "2294             Spirited Away           8.3       8.105867        3840\n",
       "2731    The Godfather: Part II           8.3       8.079586        3338"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df[['title','vote_average','weighted_vote','vote_count']].sort_values('weighted_vote',\n",
    "                                                                          ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9481df8-dc70-4b10-8580-6e1db7b58b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>weighted_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.079586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>GoodFellas</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.976937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>Once Upon a Time in America</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.657811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3887</th>\n",
       "      <td>Trainspotting</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.591009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>Catch Me If You Can</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.557097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>Casino</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.423040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>American Gangster</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.141396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>This Is England</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.739664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>American Hustle</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.717525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>Mean Streets</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.626569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title  vote_average  weighted_vote\n",
       "2731       The Godfather: Part II           8.3       8.079586\n",
       "1847                   GoodFellas           8.2       7.976937\n",
       "1663  Once Upon a Time in America           8.2       7.657811\n",
       "3887                Trainspotting           7.8       7.591009\n",
       "883           Catch Me If You Can           7.7       7.557097\n",
       "892                        Casino           7.8       7.423040\n",
       "281             American Gangster           7.4       7.141396\n",
       "4041              This Is England           7.4       6.739664\n",
       "1149              American Hustle           6.8       6.717525\n",
       "1243                 Mean Streets           7.2       6.626569"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_sim_movie(df, sorted_ind, title_name, top_n=10):\n",
    "    title_movie = df[df['title'] == title_name]\n",
    "    title_index = title_movie.index.values\n",
    "    \n",
    "    # top_n의 2배에 해당하는 쟝르 유사성이 높은 index 추출 \n",
    "    similar_indexes = sorted_ind[title_index, :(top_n*2)]\n",
    "    similar_indexes = similar_indexes.reshape(-1)\n",
    "# 기준 영화 index는 제외\n",
    "    similar_indexes = similar_indexes[similar_indexes != title_index]\n",
    "    \n",
    "    # top_n의 2배에 해당하는 후보군에서 weighted_vote 높은 순으로 top_n 만큼 추출 \n",
    "    return df.iloc[similar_indexes].sort_values('weighted_vote', ascending=False)[:top_n]\n",
    "\n",
    "similar_movies = find_sim_movie(movies_df, genre_sim_sorted_ind, 'The Godfather',10)\n",
    "similar_movies[['title', 'vote_average', 'weighted_vote']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98c4d86-d7f4-453f-b298-906574b3f40f",
   "metadata": {},
   "source": [
    "## Surprise 를 이용한 추천 시스템 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fde37df8-f62b-45d6-aed1-eefa03031248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in c:\\program files\\python310\\lib\\site-packages (69.1.1)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.4/65.4 kB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: wheel\n",
      "Successfully installed wheel-0.42.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade setuptools wheel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "685b34ba-27ce-4fd6-b4fb-1b591b3d5900",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Using cached scikit-surprise-1.1.3.tar.gz (771 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from scikit-surprise) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from scikit-surprise) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from scikit-surprise) (1.12.0)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py): started\n",
      "  Building wheel for scikit-surprise (setup.py): finished with status 'done'\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.3-cp310-cp310-win_amd64.whl size=1081863 sha256=95baae23ef9dd22a60e4028e542450bcb69dfff34b426af4ff21550dcc4b5e41\n",
      "  Stored in directory: c:\\users\\admin\\appdata\\local\\pip\\cache\\wheels\\a5\\ca\\a8\\4e28def53797fdc4363ca4af740db15a9c2f1595ebc51fb445\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise\n",
      "Successfully installed scikit-surprise-1.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad87131d-b68a-4d02-bd64-2bfb816606dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import surprise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df388f96-594c-4cc1-844d-5cf09acf3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset \n",
    "from surprise import accuracy \n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a1357a-829f-49a0-8588-d525fbf2f81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] "
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to C:\\Users\\admin/.surprise_data/ml-100k\n"
     ]
    }
   ],
   "source": [
    "data = Dataset.load_builtin('ml-100k')\n",
    "# 수행 시마다 동일하게 데이터를 분할하기 위해 random_state 값 부여\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d15ee3a-694d-49e5-b4f0-c934bf2e45b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x2857fdcb520>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD(random_state=0)\n",
    "algo.fit(trainset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c403b9-a61a-40a1-b48c-8c8a7807d34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction type : <class 'list'>  size: 25000\n",
      "prediction 결과의 최초 5개 추출\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='120', iid='282', r_ui=4.0, est=3.5114147666251547, details={'was_impossible': False}),\n",
       " Prediction(uid='882', iid='291', r_ui=4.0, est=3.573872419581491, details={'was_impossible': False}),\n",
       " Prediction(uid='535', iid='507', r_ui=5.0, est=4.033583485472447, details={'was_impossible': False}),\n",
       " Prediction(uid='697', iid='244', r_ui=5.0, est=3.8463639495936905, details={'was_impossible': False}),\n",
       " Prediction(uid='751', iid='385', r_ui=4.0, est=3.1807542478219157, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = algo.test( testset )\n",
    "print('prediction type :',type(predictions), ' size:',len(predictions))\n",
    "print('prediction 결과의 최초 5개 추출')\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "113bdc3a-fbb6-494f-bf3b-2853184b1cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('120', '282', 3.5114147666251547),\n",
       " ('882', '291', 3.573872419581491),\n",
       " ('535', '507', 4.033583485472447)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (pred.uid, pred.iid, pred.est) for pred in predictions[:3] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76afbe55-33f2-42b9-8d26-2a3f168f1f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = None   est = 4.49   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# 사용자 아이디, 아이템 아이디는 문자열로 입력해야 함. \n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "pred = algo.predict(uid, iid)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7df02212-da1c-4c2d-8b6b-948aac6c6873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9466860806937948"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea825bd-5c55-473f-a121-a2d69e3810b9",
   "metadata": {},
   "source": [
    "## Surprise 주요 모듈 소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac54e83a-f9c8-4eb4-909d-b1a97a4922e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec8f6f5b-339b-4d53-898b-9ca099398fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "# ratings_noh.csv 파일로 unload 시 index 와 header를 모두 제거한 새로운 파일 생성.  \n",
    "ratings.to_csv('./ml-latest-small/ratings_noh.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d346c642-2dba-45dc-bdbf-345ff9af19a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader\n",
    "\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
    "data=Dataset.load_from_file('./ml-latest-small/ratings_noh.csv',reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f8918e3-7db7-4c99-8a35-1d2e716cc699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
    "\n",
    "# 수행시마다 동일한 결과 도출을 위해 random_state 설정 \n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "\n",
    "# 학습 데이터 세트로 학습 후 테스트 데이터 세트로 평점 예측 후 RMSE 평가\n",
    "algo.fit(trainset) \n",
    "predictions = algo.test( testset )\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32acda15-8408-4741-9bca-f44b6a11fda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "ratings = pd.read_csv('./ml-latest-small/ratings.csv') \n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# ratings DataFrame 에서 컬럼은 사용자 아이디, 아이템 아이디, 평점 순서를 지켜야 합니다. \n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
    "\n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "algo.fit(trainset) \n",
    "predictions = algo.test( testset )\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5dfab-77c2-4095-899b-b10dc4978b14",
   "metadata": {},
   "source": [
    "## Surprise 를 이용한 개인화 영화 추천 시스템 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543ae8f-2a1d-4ecd-8ff4-95240895bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f331d67-64e7-4df3-a677-17229176115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
